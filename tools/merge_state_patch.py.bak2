from __future__ import annotations

import argparse
from pathlib import Path
from typing import Any

from _common import (
    dump_json,
    get_repo_root,
    iso_today,
    load_json,
    normalize_chapter_id,
    safe_write_text,
    setup_logger,
)


def _deep_merge(current: Any, patch: Any, *, key: str | None = None) -> Any:
    if key == "open_loops" and isinstance(current, list) and isinstance(patch, list):
        return _merge_open_loops(current, patch)
    if isinstance(current, dict) and isinstance(patch, dict):
        out = dict(current)
        for k, v in patch.items():
            out[k] = _deep_merge(out.get(k), v, key=k)
        return out
    return patch


def _merge_open_loops(current: list[Any], patch: list[Any]) -> list[Any]:
    patch_items = [x for x in patch if isinstance(x, dict) and "id" in x]
    if len(patch_items) != len(patch):
        return patch

    current_by_id: dict[str, dict[str, Any]] = {}
    current_order: list[str] = []
    passthrough: list[Any] = []
    for item in current:
        if isinstance(item, dict) and "id" in item:
            loop_id = str(item["id"])
            current_by_id[loop_id] = item
            current_order.append(loop_id)
        else:
            passthrough.append(item)

    merged_by_id: dict[str, Any] = {k: dict(v) for k, v in current_by_id.items()}
    seen_patch_ids: set[str] = set()

    for item in patch_items:
        loop_id = str(item["id"])
        if loop_id in merged_by_id:
            merged_by_id[loop_id] = _deep_merge(merged_by_id[loop_id], item, key=None)
        else:
            merged_by_id[loop_id] = item
            current_order.append(loop_id)
        seen_patch_ids.add(loop_id)

    out: list[Any] = []
    for loop_id in current_order:
        out.append(merged_by_id[loop_id])
    out.extend(passthrough)
    return out


def _normalize_patch_chapter(patch_obj: dict[str, Any], log) -> bool:
    meta = patch_obj.get("meta")
    if not isinstance(meta, dict) or "current_chapter" not in meta:
        return True

    raw = meta.get("current_chapter")
    try:
        normalized = normalize_chapter_id(raw)
    except ValueError as e:
        log.error("Invalid meta.current_chapter in patch: %r (%s)", raw, e)
        return False

    if normalized != raw:
        log.warning("Normalized patch meta.current_chapter from %r to %r", raw, normalized)
        meta["current_chapter"] = normalized
    return True


def main() -> int:
    parser = argparse.ArgumentParser(
        description="Deep-merge state/state_patch.json into state/current_state.json."
    )
    parser.add_argument(
        "--date", default=iso_today(), help="Date for backup filename (YYYY-MM-DD). Default: today."
    )
    parser.add_argument(
        "--patch", default=None, help="Patch path (default: state/state_patch.json)."
    )
    parser.add_argument(
        "--state", default=None, help="State path (default: state/current_state.json)."
    )
    parser.add_argument("--verbose", action="store_true", help="Verbose logging.")
    args = parser.parse_args()

    root = get_repo_root()
    run_dir = root / "runs" / args.date
    run_dir.mkdir(parents=True, exist_ok=True)
    log = setup_logger(
        "merge_state_patch", log_file=run_dir / "merge_state_patch.log", verbose=args.verbose
    )

    patch_path = Path(args.patch) if args.patch else (root / "state" / "state_patch.json")
    state_path = Path(args.state) if args.state else (root / "state" / "current_state.json")
    backup_dir = root / "state" / "backups"
    backup_dir.mkdir(parents=True, exist_ok=True)
    backup_path = backup_dir / f"{args.date}_current_state.json"

    if not patch_path.exists():
        log.error("Patch not found: %s", patch_path.as_posix())
        return 2
    if not state_path.exists():
        log.error("State not found: %s", state_path.as_posix())
        return 2

    try:
        patch_obj = load_json(patch_path)
    except Exception as e:  # noqa: BLE001
        log.error("Failed to parse patch JSON: %s", e)
        return 2
    if not isinstance(patch_obj, dict):
        log.error("Patch JSON must be an object/dict.")
        return 2

    if not _normalize_patch_chapter(patch_obj, log):
        return 2

    try:
        state_obj = load_json(state_path)
    except Exception as e:  # noqa: BLE001
        log.error("Failed to parse current_state JSON: %s", e)
        return 2
    if not isinstance(state_obj, dict):
        log.error("current_state JSON must be an object/dict.")
        return 2

    safe_write_text(
        backup_path,
        state_path.read_text(encoding="utf-8", errors="replace"),
        backup=False,
    )
    log.info("backed up current_state to: %s", backup_path.as_posix())

    merged = _deep_merge(state_obj, patch_obj, key=None)
    dump_json(state_path, merged, backup=False)
    log.info("merged patch into current_state: %s", state_path.as_posix())
    return 0


if __name__ == "__main__":
    raise SystemExit(main())

